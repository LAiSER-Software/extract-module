# LAiSER Skill-Extraction v0.2.2 – Phanindra's Notes
 
## 1. Plan
The goal of the refactor is to ensure that the extractor returns 
- a clean table with the following columns
```
Research ID, Description, Raw Skill, Knowledge Required, Task Abilities, Skill Tag, Correlation Coefficient
```
- build a taxonomy-aware approach to extract skills so that the extracted skills are aligned with the ESCO taxonomy before LLM inference for  KSAs.

For every input row the pipeline will:
1. Build the description string from the specified text columns.
2. Run a FAISS semantic search against the ESCO taxonomy to obtain the top-k similar skills.
3. For each retrieved skill:
   • Record the skill name as *Raw Skill* and its similarity score as *Correlation Coefficient*.
   • Create the *Skill Tag* in the form `ESCO.<index>` where *index* is the row position in the ESCO list.
   • When a GPU/vLLM model is available, query the LLM with a compact prompt to obtain lists for *Knowledge Required* and *Task Abilities*.
4. Assemble all results into a `pandas.DataFrame` adhering to the new seven-column schema and return it directly.

Legacy alignment code is temporarily retained and will be removed once the new flow is fully validated.

## 2. Changes implemented so far
| File | Summary of edits |
|------|------------------|
| `laiser/utils.py` | `get_top_esco_skills()` now returns `{Skill, index, score}` (includes taxonomy index). |
| `laiser/llm_methods.py` | Added `get_ksa_details()` helper that calls vLLM and parses JSON lists for Knowledge Required & Task Abilities. Added supporting imports. |
| `laiser/skill_extractor.py` |
|  • imports | Now imports `get_ksa_details`. |
|  • `__init__` | Ensures `self.index` is always defined; loads or builds FAISS index lazily. |
|  • `build_faiss_index_esco` & `load_faiss_index_esco` | Converted to instance methods, use `self.skill_names`, save/load index inside `laiser/input`, update `self.index` field. |
|  • `get_top_esco_skills` | Re-written as an instance method using cached SentenceTransformer & FAISS; returns `{Skill, index, score}`. |
|  • `extractor` | Injected new pipeline at the very top that executes the plan and returns the new-format DataFrame; falls back to legacy flow only if no result rows are produced. |

## 3. Pending / next steps
1. Remove or deprecate legacy `align_skills`, `align_KSAs`, and the old code path once the new output is validated.
2. Add unit tests covering:
   • FAISS search output structure.
   • `get_ksa_details` JSON parsing robustness.
   • End-to-end `Skill_Extractor.extractor` on CPU-only and GPU paths.
3. Update `README.md` and examples to showcase the new output format. 
4. Investigate CPU-only fallback for Knowledge/Task inferences (e.g., smaller LLM or empty lists with warning).
5. Persist ESCO vector index in a cloud-ready vector store (see TODO comment) and drop local FAISS build step.
6. Profile & batch calls to `get_ksa_details` for speed and cost (possibly pass multiple prompts to vLLM at once).
7. Clean up duplicate `import json` lines in `llm_methods.py`.
8. Verify that `requirements.txt` includes `faiss-cpu` for environments without GPU FAISS.
9. Current implementation calls the LLM for each skill separately. We can batch the calls to the LLM to reduce the cost. (This is a TODO for the next(v0.3) version)

Once the above are complete, we can tag a minor version bump and remove deprecated code. 