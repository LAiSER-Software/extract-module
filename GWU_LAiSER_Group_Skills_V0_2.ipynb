{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpbbOpe-lifa"
      },
      "source": [
        "## Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ug3jKGjodBg"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIDQPcuKoqEa"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK65eWYQo6TS"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHaGD3X4pHuB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "import openai\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skjBA_yBpKca"
      },
      "outputs": [],
      "source": [
        "# If using Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "base_path = '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAPdtoHN8PEB"
      },
      "source": [
        "## Convert to jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDS3yq0NvouT"
      },
      "outputs": [],
      "source": [
        "osn_comp_df = pd.read_csv(f'{base_path}/osn_comp.csv')\n",
        "osn_pub_df = pd.read_csv(f'{base_path}/osn_public_rel.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eARvuhqZ8Q1z"
      },
      "outputs": [],
      "source": [
        "# Create a list of dictionaries with the required format\n",
        "jsonl_list = []\n",
        "for index, row in osn_comp_df.iterrows():\n",
        "    jsonl_dict = {\n",
        "        \"prompt\": row['RSD Name'],\n",
        "        \"completion\": row['Skill Statement']\n",
        "    }\n",
        "    jsonl_list.append(jsonl_dict)\n",
        "\n",
        "# Save the list of dictionaries to a JSONL file\n",
        "with open(\"osn_comp.jsonl\", \"w\") as jsonl_file:\n",
        "    for jsonl_dict in jsonl_list:\n",
        "        jsonl_file.write(f'{{\"prompt\": \"{jsonl_dict[\"prompt\"]}\", \"completion\": \"{jsonl_dict[\"completion\"]}\"}}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "418vJil7K7Y2"
      },
      "outputs": [],
      "source": [
        "# Create a list of dictionaries with the required format\n",
        "jsonl_list = []\n",
        "for index, row in osn_pub_df.iterrows():\n",
        "    jsonl_dict = {\n",
        "        \"prompt\": row['RSD Name'],\n",
        "        \"completion\": row['Skill Statement']\n",
        "    }\n",
        "    jsonl_list.append(jsonl_dict)\n",
        "\n",
        "# Save the list of dictionaries to a JSONL file\n",
        "with open(\"osn_pub.jsonl\", \"w\") as jsonl_file:\n",
        "    for jsonl_dict in jsonl_list:\n",
        "        jsonl_file.write(f'{{\"prompt\": \"{jsonl_dict[\"prompt\"]}\", \"completion\": \"{jsonl_dict[\"completion\"]}\"}}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGcx3NO1zDYB"
      },
      "source": [
        "##Import Taxonomy Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE2eWrxFRtrg"
      },
      "source": [
        "###OSN Data for Skills"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybgSBhtqpcAr"
      },
      "source": [
        "OSN Computer Programmer Data - from WGU\n",
        "\n",
        "https://osmt.wgu.edu/api/collections/ba52215b-5cae-4ce6-93de-a8684bb8bf56"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xexHCYgw3Czf"
      },
      "outputs": [],
      "source": [
        "osn_comp_df = pd.read_csv(f'{base_path}/osn_comp.csv')\n",
        "osn_comp_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncMLVCwYpvn8"
      },
      "source": [
        "OSN Industrial Engineering Data - from WGU\n",
        "\n",
        "https://osmt.wgu.edu/api/collections/79399575-3936-47f2-8848-b95a2d39dfd5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slx-gZsLcBi0"
      },
      "outputs": [],
      "source": [
        "osn_indus_df = pd.read_csv(f'{base_path}/osn_indust.csv')\n",
        "osn_indus_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECeWaVQuEwoF"
      },
      "source": [
        "OSN Publc Relations - from WGU\n",
        "\n",
        "https://osmt.wgu.edu/api/collections/3db5cb7b-6e03-4d96-8e95-83d15d1525a8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wzovr_8EjqY"
      },
      "outputs": [],
      "source": [
        "osn_pub_df = pd.read_csv(f'{base_path}/osn_public_rel.csv')\n",
        "osn_pub_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXsa7EZYzwYx"
      },
      "source": [
        "##Job Descriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUTTMCEImXzE"
      },
      "source": [
        "Job descriptions taken from Google Jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urxgk6tlYSK4"
      },
      "outputs": [],
      "source": [
        "# Create a jobs df\n",
        "jobs_df = pd.read_csv(f'{base_path}/jobs_df.csv')\n",
        "print(\"Head of DataFrame with 36 job descriptions:\\n\", jobs_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv5dCO2TagZR"
      },
      "source": [
        "### Input from user to add a new job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxjtWNNGVEwm"
      },
      "outputs": [],
      "source": [
        "def add_job(df):\n",
        "    # Get input for the new job description from the user\n",
        "    new_job = input(\"Enter a new job description: \")\n",
        "\n",
        "    # Get the current maximum job_id\n",
        "    max_job_id = df['job_id'].max()\n",
        "\n",
        "    # Increment the job_id for the new job\n",
        "    new_job_id = max_job_id + 1\n",
        "\n",
        "    # Add the new job to the jobs_df\n",
        "    df = pd.concat([df, pd.DataFrame([{'job_id': new_job_id, 'job_desc': new_job}])], ignore_index=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7sS8IaNYrQj"
      },
      "outputs": [],
      "source": [
        "# Add the new job to the DataFrame\n",
        "jobs_df = add_job(jobs_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZI9UsL8aXNC"
      },
      "outputs": [],
      "source": [
        "jobs_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmTUizNSzN7C"
      },
      "source": [
        "##Instantiate LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llibUvYAy52v"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNZg607zeaV"
      },
      "source": [
        "## Extracting skills from jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IrFkXfpSdAm"
      },
      "source": [
        "#### Fine Tuned Model for comp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrXmZI4iSg-x"
      },
      "outputs": [],
      "source": [
        "fine_tuned_model_comp = \"ft:davinci-002:personal::8IIFVUbf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfpYfqxoRgiR"
      },
      "source": [
        "####Embedding and Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsbFwl23Pkur"
      },
      "outputs": [],
      "source": [
        "# Calculate embeddings for a given text. nlp is the model to do embedding\n",
        "def get_embedding(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    if len(doc) == 0:\n",
        "        return np.zeros(300)  # Return zeros for empty texts\n",
        "    return np.mean([word.vector for word in doc], axis=0)\n",
        "\n",
        "# Calculate cosine similarity between 2 vectors\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51BovoPoRl_1"
      },
      "source": [
        "####Use finetuned model to extract skills from job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5Dfl9VOrMsD"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "api_key = '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'\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def extract_skills_from_job_description(job_description, fine_tuned_model_id):\n",
        "\n",
        "    # Use the fine-tuned model to extract skills from the job description\n",
        "    response = client.completions.create(\n",
        "        model=fine_tuned_model_id,\n",
        "        prompt=f'''Name all the skills present in the following job description in a single list.\n",
        "                    Response should have only the skills, no other information or words.\n",
        "                    Skills should be keywords, each being no more than 3 words.:\n",
        "                    This is the Job Description:\n",
        "                    {job_description}\n",
        "\n",
        "                    Skills:\n",
        "                    ''',\n",
        "        max_tokens = 75,  # Maximum returned tokens required\n",
        "        temperature = 0.0 # Indicates variation in the model\n",
        "    )\n",
        "\n",
        "    # Get the skills the fine-tuned model returns\n",
        "    extracted_skills = response.choices[0].text.strip()\n",
        "\n",
        "    # Split the extracted skills into a list of unique words\n",
        "    extracted_skills_set = set([word.lstrip('-').strip() for word in extracted_skills.split(\"\\n\")])\n",
        "\n",
        "    #  Join the unique words with commas\n",
        "    unique_extracted_skills = list(extracted_skills_set)\n",
        "\n",
        "    return unique_extracted_skills"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "165nOJRuR3cR"
      },
      "source": [
        "#### match extracted skills to OSN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lle8XRQxzhC2"
      },
      "outputs": [],
      "source": [
        "def compare_skills_with_glove(extracted_skills_list, taxn_source, similarity_threshold=0.65):\n",
        "    # Get the skills (keywords column) from taxonomies\n",
        "    # OSN data have separate dfs for keywords\n",
        "    key_series = taxn_source['RSD Name']\n",
        "\n",
        "    # Create an empty list for the skills that match\n",
        "    skill_matches = []\n",
        "\n",
        "    # Load GloVe vectors using spaCy's en_vectors_web_lg model\n",
        "    nlp_glove = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "    # Initialize an empty set to track previously matched skills\n",
        "    matched_skills_set = set()\n",
        "\n",
        "    # Iterate through each skill in extracted_skills_list\n",
        "    for extracted_skill in extracted_skills_list:\n",
        "        # Check if extracted_skill contains non-whitespace characters\n",
        "        if extracted_skill.strip():\n",
        "            # Calculate GloVe embedding for the extracted skill\n",
        "            extracted_embedding = get_embedding(extracted_skill, nlp_glove)\n",
        "\n",
        "            # Initialize variables to store the best match and its similarity score\n",
        "            best_match = None\n",
        "            best_similarity = 0.0\n",
        "\n",
        "            # Iterate through each keyword in key_series (skills from taxonomy)\n",
        "            for key_skill in key_series:\n",
        "                # Calculate GloVe embedding for the keywords/skills from taxn\n",
        "                key_embedding = get_embedding(key_skill, nlp_glove)\n",
        "\n",
        "                # Calculate cosine similarity between extracted skill and keyword skill\n",
        "                similarity = cosine_similarity(extracted_embedding, key_embedding)\n",
        "\n",
        "                # If the similarity score is above the threshold and the skill is not already matched\n",
        "                if similarity >= similarity_threshold and key_skill not in matched_skills_set:\n",
        "                    best_similarity = similarity\n",
        "                    best_match = key_skill\n",
        "\n",
        "                    # Update the set of previously matched skills\n",
        "                    matched_skills_set.add(key_skill)\n",
        "\n",
        "            # If a best match was found, add it to the list of matched skills\n",
        "            if best_match:\n",
        "                skill_matches.append(best_match)\n",
        "\n",
        "    return skill_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ReJPJmXSotJ"
      },
      "source": [
        "#### Extract and Match skills to OSN for jobs df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBhigz_FRBjc"
      },
      "outputs": [],
      "source": [
        "def match_skills_for_job_df(jobs_df, fine_tuned_model_id, taxn_source, similarity_threshold=0.65):\n",
        "    # Initialize an empty list to store the matched skills for each job\n",
        "    matched_skills_list = []\n",
        "\n",
        "    # Iterate through each row in the DataFrame\n",
        "    for job_index, job_row in jobs_df.iterrows():\n",
        "        # Extract skills from the current job description\n",
        "        extracted_skills = extract_skills_from_job_description(job_row['job_desc'], fine_tuned_model_id)\n",
        "\n",
        "        # Match the extracted skills to the taxonomy\n",
        "        job_matches = compare_skills_with_glove(extracted_skills, taxn_source, similarity_threshold)\n",
        "\n",
        "        # Create a dictionary to store the job number and its matched skills\n",
        "        job_data = {\n",
        "            \"Job Number\": job_index + 1,\n",
        "            \"Matched Skills\": job_matches\n",
        "        }\n",
        "\n",
        "        # Append the job data to the list\n",
        "        matched_skills_list.append(job_data)\n",
        "\n",
        "    # Create a DataFrame from the list of job data\n",
        "    matched_skills_df = pd.DataFrame(matched_skills_list)\n",
        "\n",
        "    return matched_skills_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d1YtZDqEdG1q"
      },
      "outputs": [],
      "source": [
        "job_skills_3 = match_skills_for_job_df(jobs_df, fine_tuned_model_comp, osn_comp_df, similarity_threshold=0.65)\n",
        "job_skills_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kho4pQiymn7U"
      },
      "outputs": [],
      "source": [
        "job_skills_3.to_csv(f'{base_path}/job_skills_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq6DnbofaPzE"
      },
      "source": [
        "#### Group Skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FHWnrRyaVev"
      },
      "outputs": [],
      "source": [
        "def find_common_skills(job_skills_df, min_matches=3):\n",
        "    # Initialize an empty list to store the common skills pairs\n",
        "    common_skills_pairs = []\n",
        "\n",
        "    # Iterate through each row in the job_skills_df DataFrame\n",
        "    for job_index, job_row in job_skills_df.iterrows():\n",
        "        current_job_number = job_row['Job Number']\n",
        "        current_job_skills = set(job_row['Matched Skills'])\n",
        "\n",
        "        # Iterate through each subsequent row in the DataFrame\n",
        "        for other_job_index, other_job_row in job_skills_df.iloc[job_index + 1:].iterrows():\n",
        "            other_job_number = other_job_row['Job Number']\n",
        "            other_job_skills = set(other_job_row['Matched Skills'])\n",
        "\n",
        "            # Calculate the number of common skills between the two jobs\n",
        "            common_skills = current_job_skills.intersection(other_job_skills)\n",
        "            num_common_skills = len(common_skills)\n",
        "\n",
        "            # If there are at least three common skills, add the pair to the list\n",
        "            if num_common_skills >= min_matches:\n",
        "                common_skills_pairs.append((current_job_number, other_job_number, list(common_skills)))\n",
        "\n",
        "    # Convert the list of common skills pairs to a DataFrame\n",
        "    skills_common_df = pd.DataFrame(common_skills_pairs, columns=['Job Number 1', 'Job Number 2', 'Common Skills'])\n",
        "\n",
        "    return skills_common_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWCKu73Frr7_"
      },
      "outputs": [],
      "source": [
        "common_skills_3 = find_common_skills(job_skills_3)\n",
        "common_skills_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o13Fpl96twCb"
      },
      "source": [
        "## Count Common Skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1exAEWezD_p"
      },
      "outputs": [],
      "source": [
        "# Create count_skills DataFrame\n",
        "count_skills = pd.DataFrame(columns=['Count', 'Jobs', 'Common Skills'])\n",
        "\n",
        "# Iterate through each row in common_skills_3\n",
        "for index, row in common_skills_3.iterrows():\n",
        "    common_skills_set = set(row['Common Skills'])\n",
        "    count = 0\n",
        "    job_numbers = []\n",
        "\n",
        "    # Iterate through each row in job_skills_3\n",
        "    for job_index, job_row in job_skills_3.iterrows():\n",
        "        matched_skills_set = set(job_row['Matched Skills'])\n",
        "\n",
        "        # Check if common skills are a subset of matched skills\n",
        "        if common_skills_set.issubset(matched_skills_set):\n",
        "            count += 1\n",
        "            job_numbers.append(job_row['Job Number'])\n",
        "\n",
        "    # Concatenate the result to count_skills DataFrame\n",
        "    count_skills = pd.concat([count_skills, pd.DataFrame({\n",
        "        'Count': [count],\n",
        "        'Jobs': [job_numbers],\n",
        "        'Common Skills': [row['Common Skills']]\n",
        "    })])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7hr9RxF0r3r"
      },
      "outputs": [],
      "source": [
        "# Drop Duplicates\n",
        "count_skills = count_skills[~count_skills.astype(str).duplicated()]\n",
        "# Reset index\n",
        "count_skills = count_skills.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsYiEFpXzkM-"
      },
      "outputs": [],
      "source": [
        "count_skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5KJov6f2Rrc"
      },
      "outputs": [],
      "source": [
        "count_skills.to_csv('/content/drive/MyDrive/count_skills_osn_prog.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKNezJHwCFnA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}